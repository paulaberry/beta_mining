#!/usr/bin/env python3
#
# This script provides an interface that combines the functions in the
# "BetaMining" package to analyze .pdb files of interest.
import prody
import numpy as np
import pandas as pd

from Bio.PDB.PDBParser import PDBParser
p = PDBParser(PERMISSIVE=1)

from sklearn.metrics import pairwise_distances

from biopandas.pdb import PandasPdb
import datetime
import os
import sys
import math
import re
import json
import os
import tarfile
import gzip
import shutil
import glob
from pathlib import Path

import beta_mining
from beta_mining import beta_mining_algorithm
from beta_mining import beta_mining_functions

def polymer_df(pdb_meta_dict, pdb_object):
  """returns a dataframe of polymer metadata and residue information from the
  PDB file. Returned dataframe consists of columns that identify the
  file, origin, and version of PDB prediction file the values are calculated from
  ("database", "id_code", "accession", "full_title", "depo_date") and metadata
  about the organism and protein the prediction file represents
  ("organism_taxid", "organism_scientific", "full_name", "fragment",
  "fragment_aa", "structure_aa", "aa_identity") and values for
  alpha-carbon coordinates ("x", "y", "z")

  Keyword arguments:
  pdb_meta_dict -- a dictionary of keys and values for dataframe columns
  pdb_file -- the filepath for the PDB file
  """
  df = pdb_object.loc[pdb_object["atom_name"] == "CA"]
  column_list_order = list(pdb_meta_dict.keys()) + ["residue_name", "residue_number", "x_coord", "y_coord", "z_coord", "b_factor"]
  df = df.assign(**pdb_meta_dict)
  df = df.reindex(columns = column_list_order)
  if pdb_meta_dict["full_title"].lower().find("alphafold") != -1:
      df = df.rename(columns = {"b_factor": "plddt"})
  return df


def calculation_df(prody_model, residue_offset, secondary_structures, units = "degrees"):
  """returns a dataframe of relative residue numbers and phi, psi, omega, twist,
  and absolute residue numbers for a protein; returns a series of secondary
  structure symbols for

  Keyword arguments:
  prody_model -- a ProDy AtomGroup object
  pdb_meta_dict_offset -- the value for the residue offset to find the absolute
  residue number in a protein with multiple fragment PDB files
  """
  secondary_structure_dictionary = {}
  if units.lower()[0] == "d":
    radians = False
  elif units.lower()[0] == "r":
    radians = True

  symbol_list = []
  ramachandran_region_list = []
  data = []
  for residue in prody_model.iterResidues():
    symbol = "-"
    secondary_structure = "None"
    try:
      phi = prody.calcPhi(residue, radians, None)
      psi = prody.calcPsi(residue, radians, None)
      omega = prody.calcOmega(residue, radians, None)
      twist = psi - abs(phi)
      dihedrals_dictionary = {"phi": phi, "psi": psi, "omega": omega}
    except:
      phi, psi, omega, twist = "", "", "", ""
      continue
    else:
      for structure in secondary_structures:
        dihedrals = list(structure.keys() & dihedrals_dictionary.keys())
        if all(structure[d][units][0] <= dihedrals_dictionary[d] <= structure[d][units][1] for d in dihedrals) == True:
          secondary_structure = structure["name"]
          symbol = structure["symbol"]
          break

    finally:
      symbol_list.append(symbol)
      data.append((residue.getResnum(), int(residue.getResnum() + residue_offset), phi, psi, omega, twist, secondary_structure))
      if secondary_structure in secondary_structure_dictionary:
        secondary_structure_dictionary[secondary_structure].append(residue.getResnum())
      else:
        secondary_structure_dictionary[secondary_structure] = [residue.getResnum()]

  symbol_series = pd.Series(symbol_list)
  df = pd.DataFrame(data, columns = ["residue_number",
                                         "absolute_residue_number",
                                         "phi",
                                         "psi",
                                         "omega",
                                         "twist",
                                         "secondary_structure"])

  secondary_structure_dictionary["twist"] = dict(zip(df.residue_number, df.twist))
  return df, symbol_series, secondary_structure_dictionary

def contacts_df(pdb_dataframe, features_json, residue_features_dictionary, target_list):
  """returns a dataframe of residue numbers and a column of residues with which
  they are in contact according to target features, and a dictionary of boolean
  masks of which residues should be included or excluded from the final filter

  Keyword arguments:
  pdb_dataframe -- the dataframe generated using the "ATOM" entries in the PDB file
  features_json -- the dictionary generated from the "target_region_features" of the .json file
  residue_features_dictionary -- the dictionary generated by calculation_df,
  with key:value pairs of secondary structure and then lists of residue numbers
  that are assigned to that structure
  target_list -- a list of target region names for which to search the protein
  """
  coords_df = pdb_dataframe.loc[pdb_dataframe["atom_name"] == "CA"][["residue_number", "x_coord", "y_coord", "z_coord"]].reset_index(drop=True)
  residue_numbers_list = coords_df["residue_number"].values.tolist()
  distance_matrix = pairwise_distances(coords_df, metric = "euclidean")
  column_names = ["residue_number"]

  series_mask_dictionary = {"include": [], "exclude": []}

  for target in features_json:
    if target["name"] in target_list:
      for condition in series_mask_dictionary.keys():
        if "contacts" in target[condition].keys():
          for contact_type in target[condition]["contacts"]:
            column_names.append(contact_type["name"])
            contact_max_distance = contact_type["max_distance"]
            contact_min_distance = contact_type["min_distance"]
            contact_flank = contact_type["excluded_flank"]
            contact_matrix = np.add(np.triu(distance_matrix, k = (1 + contact_flank)),np.tril(distance_matrix, k = -1 * (1 + contact_flank)))
            contact_matrix = np.where(contact_matrix > contact_max_distance, 0, contact_matrix)
            contact_matrix = np.where(contact_matrix < contact_min_distance, 0, contact_matrix)
            contact_matrix = np.where(contact_matrix > 0, 1, contact_matrix)
            if "secondary_structures" in contact_type:
              array_idx = []
              for structure in contact_type["secondary_structures"]:
                array_idx.extend(residue_features_dictionary[structure])
              array_idx = list(np.asarray(list(set(residue_numbers_list) - set(array_idx))) - 1)
              contact_matrix[:,array_idx] = 0
            if contact_type["target_name"] != ["all"]:
              target_idx = []
              for label in contact_type["target_name"]:
                target_idx.extend(residue_features_dictionary[label])
              target_idx = list(np.asarray(list(set(residue_numbers_list) - set(target_idx))) - 1)
              target_matrix = contact_matrix
              target_matrix[array_idx,:] = 0
            else:
              target_matrix = contact_matrix

          contacts_df = pd.DataFrame(data = contact_matrix, columns = residue_numbers_list)
          coords_df[contact_type["name"]] = contacts_df.apply(lambda row: row[row == 1.0].index.tolist(), axis = 1)
          series_mask_dictionary[condition].append((pd.Series(np.sum(target_matrix, axis = 1).astype(bool)),contact_type["mask_symbol"]))

  contacts_dataframe = coords_df[column_names]
  return contacts_dataframe, series_mask_dictionary

def attribute_filter(target_json, match_object, dihedral_dataframe):
  """returns a boolean value indicating whether a regex match should be passed
  (True) or failed (False) based on the twist values of the residue range

  Keyword arguments:
  target_json -- the target motif attribute section of the features .json
  match_object -- the match object from the regular expression search being queried
  dihedral_dataframe -- the dataframe containing the calculated dihedral angles and other attributes for the protein
  """
  available_calculation_list = list(dihedral_dataframe.columns)
  for condition in ["exclude", "include"]: # the function immediately returns False if any part fails, so exclude comes first no matter what the order is in the YAML config
    for attribute in target_json[condition]:
      if attribute in available_calculation_list:
        for func_name in target_json[condition][attribute]:
          func = getattr(pd.Series, func_name)
          if target_json[condition][attribute][func_name][0] <= func(dihedral_dataframe[attribute][dihedral_dataframe["residue_number"].isin([*range(match_object.span()[0] + 1, match_object.span()[1] + 2)])]) <= target_json[condition][attribute][func_name][1]:
            if condition == "exclude":
              return False
          else:
            if condition == "include":
              return False
  return True

def attribute_calculations(config_add_attr, residue_range, poly_dataframe):
    """returns a list to be column values of calculated attributes of hit sequences based on the "additional_attributes" section of the YAML config file.

    Keyword arguments:
    config_add_attr -- dictionary calculated attributes to include from the "additional_attributes" section of the config YAML
    residue_range -- a tuple of the residue range over which to calculate the value
    poly_dataframe -- a dataframe with all per-residue values needed for the attribute calculations
    """
    pass

def create_model_metainfo(pdb_file):
    """returns a ProDy model and a dictionary of meta information about a protein, taken from the PDB file header. Also returns the amino acid sequence as a list of 1-letter codes, and a Pandas dataframe of atomic coordinates.

    Keyword arguments:
    pdb_file -- the PDB structure file
    """
    model, pdb_head = prody.parsePDB(pdb_file, header=True, model=1, meta=True)
    # using BioPandas to get matrix of PDB values and convert sequence to single letter
    af_object = PandasPdb().read_pdb(pdb_file).df["ATOM"]
    af_sequence = list(PandasPdb().read_pdb(pdb_file).amino3to1()["residue_name"])

    # decompress if needed
    if pdb_file.endswith(".gz") == True:
        uncompressed_pdb_file = gzip.open(pdb_file, "rt")
        bio_pdb = p.get_structure("XXXX", uncompressed_pdb_file)
    else:
        bio_pdb = p.get_structure("XXXX", pdb_file)

    meta_dictionary = {
        "database": pdb_head["polymers"][0].dbrefs[0].database,
        "id_code": pdb_head["polymers"][0].dbrefs[0].idcode,
        "accession": pdb_head["polymers"][0].dbrefs[0].accession,
        "full_name": pdb_head["polymers"][0].name,
        "full_title": pdb_head["title"],
        "depo_date": pdb_head["deposition_date"],
        "fragment": int((((pdb_head["polymers"][0].dbrefs[0].first[2] - pdb_head["polymers"][0].dbrefs[0].first[0]) / 200)) + 1),
        "fragment_offset": pdb_head["polymers"][0].dbrefs[0].first[2] - pdb_head["polymers"][0].dbrefs[0].first[0],
        "organism_scientific": bio_pdb.header["source"]["1"]["organism_scientific"].upper(),
        "organism_taxid": bio_pdb.header["source"]["1"]["organism_taxid"]
        }
    #pdb_file.close()

    return model, meta_dictionary, af_object, af_sequence
